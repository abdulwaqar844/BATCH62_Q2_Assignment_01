{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHSjV4qsUOmbN1OnI97Mk+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdulwaqar844/BATCH62_Q2_Assignment_01/blob/main/Assignment_05_Exploring_Gemini_2_0_Video_and_Audio_Analysis_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "H6xhxl-ej8cC"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --quiet google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GEMINI_API_KEY: str = userdata.get('GOOGLE_API_KEY')\n",
        "if(GEMINI_API_KEY):\n",
        "  print(\"API Key found\")\n",
        "else:\n",
        "  print(\"API Key not found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj039AptmOMz",
        "outputId": "d1e1c3d5-82ea-4e53-e56c-ba3ba49a71b7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initilize and configure the client\n",
        "# Select the model\n",
        "from google import genai\n",
        "from google.genai import Client\n",
        "\n",
        "client: Client = genai.Client(\n",
        "    api_key=GEMINI_API_KEY,\n",
        ")\n",
        "\n",
        "model: str = \"gemini-2.0-flash-exp\""
      ],
      "metadata": {
        "id": "KD_587hSmeNI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from google import genai\n",
        "from google.genai import Client\n",
        "client: Client = genai.Client(\n",
        "    api_key=GEMINI_API_KEY,\n",
        ")\n",
        "video_file_name = \"LangChain.mp4\"\n",
        "display_name = \"LangChain\"\n",
        "\n",
        "fileList = client.files.list()\n",
        "video_file = next((f for f in fileList if f.display_name == display_name), None)\n",
        "print('video_file',video_file)\n",
        "if video_file is None:\n",
        "    print(f\"Uploading file...\")\n",
        "    video_file = client.files.upload(path=video_file_name, display_name=display_name, resumable=True)\n",
        "    # print(f\"Completed upload: {video_file.uri}\\n\")\n",
        "else:\n",
        "    print(f\"File URI: {video_file.uri}\")\n",
        "\n",
        "while video_file.state == \"PROCESSING\":\n",
        "    time.sleep(10)\n",
        "    video_file = client.get_file(video_file.name)\n",
        "if video_file.state == \"FAILED\":\n",
        "    raise ValueError(video_file.state)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H28kBiROJthK",
        "outputId": "6ea0030f-0609-4218-81f9-949527eb0f63"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "video_file name='files/2t9mem7nw13' display_name='LangChain' mime_type='video/mp4' size_bytes=4194304 create_time=datetime.datetime(2024, 12, 28, 12, 5, 13, 698077, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2024, 12, 30, 12, 5, 13, 680809, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2024, 12, 28, 12, 5, 20, 52347, tzinfo=TzInfo(UTC)) sha256_hash=b'a4f9e2c60dacf869d2edc5c986e8ac93ab3f4cdbff83e1c0e85435f29e77d196' uri='https://generativelanguage.googleapis.com/v1beta/files/2t9mem7nw13' state='ACTIVE' video_metadata={'videoDuration': '169s'} error=None\n",
            "File URI: https://generativelanguage.googleapis.com/v1beta/files/2t9mem7nw13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "response = client.models.generate_content(\n",
        "  model='gemini-1.5-flash-002',\n",
        "  contents=[\n",
        "    types.Part.from_text('What is shown in this Video?'),\n",
        "    types.Part.from_uri(video_file.uri , video_file.mime_type)\n",
        "  ]\n",
        ")\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "id": "sD0gT_C4rpre",
        "outputId": "c5be4ca4-2e30-4f35-b327-16517fb9be8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This video explains Langchain, an open-source framework that allows AI developers to combine LLMs (large language models) like GPT-4 with external sources of computation and data.  It's available as a Python or Typescript package.\n",
            "\n",
            "The video uses the example of wanting to know something from your own document (a book, PDF, database, etc.). Langchain helps connect a large language model like GPT-4 to your own data sources. Instead of just pasting a text snippet into a prompt, Langchain allows referencing an entire database filled with your data.\n",
            "\n",
            "After getting the needed information, Langchain helps with actions like sending emails with specific information.  The process involves taking your document, slicing it into smaller chunks, and storing those chunks in a vector database as embeddings (vector representations of the text).\n",
            "\n",
            "Langchain builds language model applications that follow a general pipeline:  a user asks a question, the question is sent to the language model, a vector representation is used for a similarity search in the vector database, relevant chunks of information are fetched and fed to the language model, and then the language model provides an answer or takes an action.  The video notes that these applications are data-aware and agentive (able to take actions beyond providing answers to questions).  Several practical use cases are shown, including flight booking, money transfers, studying, and coding.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}